{"cells":[{"cell_type":"code","source":["%pip install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"outputs_hidden":true}},"id":"fe86001e-b951-4a66-8f45-830e5d3303ad"},{"cell_type":"code","source":["import sempy_labs\n","import sempy.fabric as fabric  \n","from sempy_labs._helper_functions import resolve_workspace_name_and_id  \n","  \n","# Get both name and ID of current workspace  \n","workspace_name, workspace_id = resolve_workspace_name_and_id()\n","# List all connections  \n","connections_df = sempy_labs.list_connections()\n","#display(connections_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9329e312-73b0-494d-bf62-3a75200a44f7"},{"cell_type":"markdown","source":["#### Check connections to help verify which connections can be reused"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7caabeeb-231f-4f6f-ab90-992e593aab8e"},{"cell_type":"code","source":["# Define the list of connection types to keep\n","connection_types_to_keep = [\"AzureDatabricksWorkspace\", \"AzureDataLakeStorage\"]\n","\n","# Filter the DataFrame for the desired connection types\n","filtered_connections_df = connections_df[connections_df[\"Connection Type\"].isin(connection_types_to_keep)]\n","\n","# Display the filtered DataFrame\n","display(filtered_connections_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false},"collapsed":false},"id":"3ed05e4b-7aa5-499b-9bc0-b261708a5e03"},{"cell_type":"markdown","source":["#### Check for existing Databricks mirrored items"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f57753a1-b9ad-4d9b-bdf3-caf3dc9a250e"},{"cell_type":"code","source":["item_list_df = fabric.list_items(workspace= workspace_id)\n","#display(item_list_df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b8701aff-e540-4dd6-94df-b199f54942e8"},{"cell_type":"code","source":["# Define the list of connection types to keep when checking for already used names\n","items_types_to_keep = [\"MirroredAzureDatabricksCatalog\"]\n","\n","# Filter the DataFrame for the desired connection types\n","item_list_filtered = item_list_df[item_list_df[\"Type\"].isin(items_types_to_keep)]\n","\n","# Display the filtered DataFrame - items created by UI will have empty description, ones created by automation with say \"Auto-created\"\n","display(item_list_filtered)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b052f439-779d-4cd2-a172-9fb8c98d2996"},{"cell_type":"code","source":["\n","item_name_nameonly = item_list_filtered[\"Display Name\"]\n","#display(item_name_nameonly)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false}},"id":"fc0c0558-3da1-45c4-99f2-c31df0f66037"},{"cell_type":"markdown","source":["#### Get Databricks mirror item definition"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"01644506-f535-4588-94f3-130db4fe31c0"},{"cell_type":"code","source":["from sempy_labs._helper_functions import get_item_definition  \n","\n","def get_databricks_mirror_definition(item_name, workspace_name):  \n","    \n","    definition = get_item_definition(  \n","        item=item_name,  \n","        type=\"MirroredAzureDatabricksCatalog\", \n","        workspace= workspace_name,  \n","        return_dataframe=False,  \n","        decode=True  \n","    )\n","    print(f'###################### {item_name} ########################')\n","    print(definition)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ea8e32aa-f210-484f-9d54-8cbfa03d38b7"},{"cell_type":"code","source":["# Print out item definitions\n","for item_name in item_name_nameonly:\n","    get_databricks_mirror_definition(item_name, workspace_name)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"source_hidden":false}},"id":"a890ba69-bc3d-448f-b0e6-ab9dea5c0e77"},{"cell_type":"markdown","source":["#### What can go wrong?"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"290dc812-b922-4eef-a708-44d438a82d10"},{"cell_type":"markdown","source":["\n","###### Azure Key Vault\n","\n","If Firewall is set to Public Access Disabled, you will get an error:\n","- _IOException: 403 {\"error\":{\"code\":\"Forbidden\",\"message\":\"Connection is not an approved private link and caller was ignored because bypass is not set to 'AzureServices' and PublicNetworkAccess is set to 'Disabled'_\n","- _IOException: 403 {\"error\":{\"code\":\"Forbidden\",\"message\":\"Public network access is disabled and request is not from a trusted service nor via an approved private link._\n","\n","To resolve this\n","- add your Workspace identity as a Secrets User or Secrets Reader to the AKV and \n","- add a Managed Private Endpoint scoped to the relevant key vault to your workspace and and approve it. Be patient, it takes a bit to sort itself out.\n","\n","\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2105338c-5fea-4ad0-af01-48e902fcb4d3"},{"cell_type":"code","source":["fabric_ws_akv = \"https://fab279akv1.vault.azure.net/\"\n","adb_ws_id_s = \"databricks-ws-id\"\n","adb_ws_token_s= \"databricks-ws-token\"\n","\n","# get the Databricks workspace id and PAT\n","dbx_workspace = notebookutils.credentials.getSecret(\n","    fabric_ws_akv,\n","    adb_ws_id_s)\n"," \n"," # will print as [REDACTED], just testing it works\n","print(f'Databricks workspace name is redacted: {dbx_workspace}')"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"520dbf8c-fdcc-4c12-93d4-9f2336fe05eb"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"127919bd-c6c4-4e51-b861-44061514ac33"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}